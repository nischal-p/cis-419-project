{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nischal-p/cis-419-project/blob/main/Advantage_Actor_Critic_for_Mario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kymJzZuo6NOz"
   },
   "source": [
    "# Cartpole learning with Actor Critic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaAGd4N18vXf"
   },
   "source": [
    "## Installing dependancies for the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "Package gcc72-7.2.1-2.59.amzn1.x86_64 already installed and latest version\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package gcc72-c++.x86_64 0:7.2.1-2.59.amzn1 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package          Arch          Version                  Repository        Size\n",
      "================================================================================\n",
      "Installing:\n",
      " gcc72-c++        x86_64        7.2.1-2.59.amzn1         amzn-main         15 M\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  1 Package\n",
      "\n",
      "Total download size: 15 M\n",
      "Installed size: 40 M\n",
      "Downloading packages:\n",
      "gcc72-c++-7.2.1-2.59.amzn1.x86_64.rpm                      |  15 MB   00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "Warning: RPMDB altered outside of yum.\n",
      "  Installing : gcc72-c++-7.2.1-2.59.amzn1.x86_64                            1/1 \n",
      "  Verifying  : gcc72-c++-7.2.1-2.59.amzn1.x86_64                            1/1 \n",
      "\n",
      "Installed:\n",
      "  gcc72-c++.x86_64 0:7.2.1-2.59.amzn1                                           \n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "!sudo yum install -y gcc72 gcc72-c++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJGB5ySZ82s_",
    "outputId": "54418584-c4d7-41f6-e6a5-daa0edb88945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym-super-mario-bros==7.3.0\n",
      "  Using cached gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting nes-py>=8.0.0\n",
      "  Using cached nes_py-8.1.8.tar.gz (76 kB)\n",
      "Requirement already satisfied: gym>=0.17.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.19.5)\n",
      "Requirement already satisfied: pyglet<=1.5.11,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.5.11)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (4.61.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=4.8.1->gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=4.8.1->gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (3.10.0.2)\n",
      "Building wheels for collected packages: nes-py\n",
      "  Building wheel for nes-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nes-py: filename=nes_py-8.1.8-cp36-cp36m-linux_x86_64.whl size=49736 sha256=bb7a0a32a0a8dc69748d5587ed75a9c7d39e11387f907300020d8ef71cf79b7e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/53/2c/fc/13b8a81dd7af319446e9b1a2cb4546d0c7b48bd1827f36362d\n",
      "Successfully built nes-py\n",
      "Installing collected packages: nes-py, gym-super-mario-bros\n",
      "Successfully installed gym-super-mario-bros-7.3.0 nes-py-8.1.8\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "No package \u001b[1mfceux\u001b[m available.\n",
      "Error: Nothing to do\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "!pip install gym-super-mario-bros==7.3.0\n",
    "!sudo yum install -y fceux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVEPqChcDGXD",
    "outputId": "d9530b84-977c-4a5f-e5f4-3ab31006d6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package xorg-x11-server-Xvfb.x86_64 0:1.17.4-18.44.amzn1 will be installed\n",
      "--> Processing Dependency: xorg-x11-server-common >= 1.17.4-18.44.amzn1 for package: xorg-x11-server-Xvfb-1.17.4-18.44.amzn1.x86_64\n",
      "--> Processing Dependency: xorg-x11-xauth for package: xorg-x11-server-Xvfb-1.17.4-18.44.amzn1.x86_64\n",
      "--> Processing Dependency: libunwind.so.8()(64bit) for package: xorg-x11-server-Xvfb-1.17.4-18.44.amzn1.x86_64\n",
      "--> Processing Dependency: libXdmcp.so.6()(64bit) for package: xorg-x11-server-Xvfb-1.17.4-18.44.amzn1.x86_64\n",
      "---> Package xorg-x11-utils.x86_64 0:7.5-6.7.amzn1 will be installed\n",
      "--> Processing Dependency: libdmx.so.1()(64bit) for package: xorg-x11-utils-7.5-6.7.amzn1.x86_64\n",
      "--> Processing Dependency: libXxf86misc.so.1()(64bit) for package: xorg-x11-utils-7.5-6.7.amzn1.x86_64\n",
      "--> Processing Dependency: libXxf86dga.so.1()(64bit) for package: xorg-x11-utils-7.5-6.7.amzn1.x86_64\n",
      "--> Processing Dependency: libXv.so.1()(64bit) for package: xorg-x11-utils-7.5-6.7.amzn1.x86_64\n",
      "--> Processing Dependency: libXinerama.so.1()(64bit) for package: xorg-x11-utils-7.5-6.7.amzn1.x86_64\n",
      "--> Running transaction check\n",
      "---> Package libXdmcp.x86_64 0:1.1.1-3.8.amzn1 will be installed\n",
      "---> Package libXinerama.x86_64 0:1.1.2-2.7.amzn1 will be installed\n",
      "---> Package libXv.x86_64 0:1.0.9-2.1.8.amzn1 will be installed\n",
      "---> Package libXxf86dga.x86_64 0:1.1.4-2.1.8.amzn1 will be installed\n",
      "---> Package libXxf86misc.x86_64 0:1.0.3-4.6.amzn1 will be installed\n",
      "---> Package libdmx.x86_64 0:1.1.3-3.7.amzn1 will be installed\n",
      "---> Package libunwind.x86_64 0:1.1-10.8.amzn1 will be installed\n",
      "---> Package xorg-x11-server-common.x86_64 0:1.17.4-18.44.amzn1 will be installed\n",
      "--> Processing Dependency: xkeyboard-config for package: xorg-x11-server-common-1.17.4-18.44.amzn1.x86_64\n",
      "--> Processing Dependency: xkbcomp for package: xorg-x11-server-common-1.17.4-18.44.amzn1.x86_64\n",
      "---> Package xorg-x11-xauth.x86_64 1:1.0.2-7.1.4.amzn1 will be installed\n",
      "--> Processing Dependency: libXmuu.so.1()(64bit) for package: 1:xorg-x11-xauth-1.0.2-7.1.4.amzn1.x86_64\n",
      "--> Running transaction check\n",
      "---> Package libXmu.x86_64 0:1.1.1-2.8.amzn1 will be installed\n",
      "--> Processing Dependency: libXt.so.6()(64bit) for package: libXmu-1.1.1-2.8.amzn1.x86_64\n",
      "---> Package xkeyboard-config.noarch 0:2.6-6.6.amzn1 will be installed\n",
      "---> Package xorg-x11-xkb-utils.x86_64 0:7.7-4.8.amzn1 will be installed\n",
      "--> Processing Dependency: libxkbfile.so.1()(64bit) for package: xorg-x11-xkb-utils-7.7-4.8.amzn1.x86_64\n",
      "--> Running transaction check\n",
      "---> Package libXt.x86_64 0:1.1.4-6.1.9.amzn1 will be installed\n",
      "---> Package libxkbfile.x86_64 0:1.0.6-1.1.6.amzn1 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package                  Arch     Version                 Repository      Size\n",
      "================================================================================\n",
      "Installing:\n",
      " xorg-x11-server-Xvfb     x86_64   1.17.4-18.44.amzn1      amzn-updates   891 k\n",
      " xorg-x11-utils           x86_64   7.5-6.7.amzn1           amzn-main      106 k\n",
      "Installing for dependencies:\n",
      " libXdmcp                 x86_64   1.1.1-3.8.amzn1         amzn-main       32 k\n",
      " libXinerama              x86_64   1.1.2-2.7.amzn1         amzn-main       20 k\n",
      " libXmu                   x86_64   1.1.1-2.8.amzn1         amzn-main       75 k\n",
      " libXt                    x86_64   1.1.4-6.1.9.amzn1       amzn-main      185 k\n",
      " libXv                    x86_64   1.0.9-2.1.8.amzn1       amzn-main       17 k\n",
      " libXxf86dga              x86_64   1.1.4-2.1.8.amzn1       amzn-main       19 k\n",
      " libXxf86misc             x86_64   1.0.3-4.6.amzn1         amzn-main       18 k\n",
      " libdmx                   x86_64   1.1.3-3.7.amzn1         amzn-main       15 k\n",
      " libunwind                x86_64   1.1-10.8.amzn1          amzn-main       72 k\n",
      " libxkbfile               x86_64   1.0.6-1.1.6.amzn1       amzn-main       78 k\n",
      " xkeyboard-config         noarch   2.6-6.6.amzn1           amzn-main      1.1 M\n",
      " xorg-x11-server-common   x86_64   1.17.4-18.44.amzn1      amzn-updates    57 k\n",
      " xorg-x11-xauth           x86_64   1:1.0.2-7.1.4.amzn1     amzn-main       36 k\n",
      " xorg-x11-xkb-utils       x86_64   7.7-4.8.amzn1           amzn-main       97 k\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  2 Packages (+14 Dependent packages)\n",
      "\n",
      "Total download size: 2.8 M\n",
      "Installed size: 8.1 M\n",
      "Downloading packages:\n",
      "--------------------------------------------------------------------------------\n",
      "Total                                               11 MB/s | 2.8 MB  00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "  Installing : libXxf86dga-1.1.4-2.1.8.amzn1.x86_64                        1/16 \n",
      "  Installing : libXinerama-1.1.2-2.7.amzn1.x86_64                          2/16 \n",
      "  Installing : libdmx-1.1.3-3.7.amzn1.x86_64                               3/16 \n",
      "  Installing : libXxf86misc-1.0.3-4.6.amzn1.x86_64                         4/16 \n",
      "  Installing : libunwind-1.1-10.8.amzn1.x86_64                             5/16 \n",
      "  Installing : libXdmcp-1.1.1-3.8.amzn1.x86_64                             6/16 \n",
      "  Installing : xkeyboard-config-2.6-6.6.amzn1.noarch                       7/16 \n",
      "  Installing : libXt-1.1.4-6.1.9.amzn1.x86_64                              8/16 \n",
      "  Installing : libXmu-1.1.1-2.8.amzn1.x86_64                               9/16 \n",
      "  Installing : 1:xorg-x11-xauth-1.0.2-7.1.4.amzn1.x86_64                  10/16 \n",
      "  Installing : libXv-1.0.9-2.1.8.amzn1.x86_64                             11/16 \n",
      "  Installing : libxkbfile-1.0.6-1.1.6.amzn1.x86_64                        12/16 \n",
      "  Installing : xorg-x11-xkb-utils-7.7-4.8.amzn1.x86_64                    13/16 \n",
      "  Installing : xorg-x11-server-common-1.17.4-18.44.amzn1.x86_64           14/16 \n",
      "  Installing : xorg-x11-server-Xvfb-1.17.4-18.44.amzn1.x86_64             15/16 \n",
      "  Installing : xorg-x11-utils-7.5-6.7.amzn1.x86_64                        16/16 \n",
      "  Verifying  : libxkbfile-1.0.6-1.1.6.amzn1.x86_64                         1/16 \n",
      "  Verifying  : 1:xorg-x11-xauth-1.0.2-7.1.4.amzn1.x86_64                   2/16 \n",
      "  Verifying  : libXv-1.0.9-2.1.8.amzn1.x86_64                              3/16 \n",
      "  Verifying  : libXt-1.1.4-6.1.9.amzn1.x86_64                              4/16 \n",
      "  Verifying  : xorg-x11-xkb-utils-7.7-4.8.amzn1.x86_64                     5/16 \n",
      "  Verifying  : xorg-x11-server-Xvfb-1.17.4-18.44.amzn1.x86_64              6/16 \n",
      "  Verifying  : xkeyboard-config-2.6-6.6.amzn1.noarch                       7/16 \n",
      "  Verifying  : libXdmcp-1.1.1-3.8.amzn1.x86_64                             8/16 \n",
      "  Verifying  : xorg-x11-server-common-1.17.4-18.44.amzn1.x86_64            9/16 \n",
      "  Verifying  : libunwind-1.1-10.8.amzn1.x86_64                            10/16 \n",
      "  Verifying  : libXmu-1.1.1-2.8.amzn1.x86_64                              11/16 \n",
      "  Verifying  : xorg-x11-utils-7.5-6.7.amzn1.x86_64                        12/16 \n",
      "  Verifying  : libXxf86misc-1.0.3-4.6.amzn1.x86_64                        13/16 \n",
      "  Verifying  : libdmx-1.1.3-3.7.amzn1.x86_64                              14/16 \n",
      "  Verifying  : libXinerama-1.1.2-2.7.amzn1.x86_64                         15/16 \n",
      "  Verifying  : libXxf86dga-1.1.4-2.1.8.amzn1.x86_64                       16/16 \n",
      "\n",
      "Installed:\n",
      "  xorg-x11-server-Xvfb.x86_64 0:1.17.4-18.44.amzn1                              \n",
      "  xorg-x11-utils.x86_64 0:7.5-6.7.amzn1                                         \n",
      "\n",
      "Dependency Installed:\n",
      "  libXdmcp.x86_64 0:1.1.1-3.8.amzn1                                             \n",
      "  libXinerama.x86_64 0:1.1.2-2.7.amzn1                                          \n",
      "  libXmu.x86_64 0:1.1.1-2.8.amzn1                                               \n",
      "  libXt.x86_64 0:1.1.4-6.1.9.amzn1                                              \n",
      "  libXv.x86_64 0:1.0.9-2.1.8.amzn1                                              \n",
      "  libXxf86dga.x86_64 0:1.1.4-2.1.8.amzn1                                        \n",
      "  libXxf86misc.x86_64 0:1.0.3-4.6.amzn1                                         \n",
      "  libdmx.x86_64 0:1.1.3-3.7.amzn1                                               \n",
      "  libunwind.x86_64 0:1.1-10.8.amzn1                                             \n",
      "  libxkbfile.x86_64 0:1.0.6-1.1.6.amzn1                                         \n",
      "  xkeyboard-config.noarch 0:2.6-6.6.amzn1                                       \n",
      "  xorg-x11-server-common.x86_64 0:1.17.4-18.44.amzn1                            \n",
      "  xorg-x11-xauth.x86_64 1:1.0.2-7.1.4.amzn1                                     \n",
      "  xorg-x11-xkb-utils.x86_64 0:7.7-4.8.amzn1                                     \n",
      "\n",
      "Complete!\n",
      "Collecting gym[box2d]==0.17.*\n",
      "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
      "Collecting pyvirtualdisplay==0.2.*\n",
      "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
      "Collecting PyOpenGL==3.1.*\n",
      "  Downloading PyOpenGL-3.1.5-py3-none-any.whl (2.4 MB)\n",
      "Collecting PyOpenGL-accelerate==3.1.*\n",
      "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gym[box2d]==0.17.*) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gym[box2d]==0.17.*) (1.19.5)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gym[box2d]==0.17.*) (1.6.0)\n",
      "Collecting box2d-py~=2.3.5\n",
      "  Downloading box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448 kB)\n",
      "Collecting EasyProcess\n",
      "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.18.2)\n",
      "Building wheels for collected packages: PyOpenGL-accelerate, gym\n",
      "  Building wheel for PyOpenGL-accelerate (setup.py): started\n",
      "  Building wheel for PyOpenGL-accelerate (setup.py): finished with status 'done'\n",
      "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp36-cp36m-linux_x86_64.whl size=521601 sha256=81f97eb33e7f5a951674d705573d43e507756e80687b7f83eb64192bdf452667\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/9c/56/14/2ba79876aab98932e150db14c912f1a7d67db8e6832ae672d1\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654041 sha256=9f83455ab599e875bc4a4b8ca0deb89c01a16384fec8ba4985a8ac81fad138c8\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/95/b0/62/af38051b97354eab5b2ff9a5fb92f5015a480745568c91e0b0\n",
      "Successfully built PyOpenGL-accelerate gym\n",
      "Installing collected packages: pyglet, gym, EasyProcess, box2d-py, pyvirtualdisplay, PyOpenGL-accelerate, PyOpenGL\n",
      "  Attempting uninstall: pyglet\n",
      "    Found existing installation: pyglet 1.5.11\n",
      "    Uninstalling pyglet-1.5.11:\n",
      "      Successfully uninstalled pyglet-1.5.11\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.21.0\n",
      "    Uninstalling gym-0.21.0:\n",
      "      Successfully uninstalled gym-0.21.0\n",
      "Successfully installed EasyProcess-0.3 PyOpenGL-3.1.5 PyOpenGL-accelerate-3.1.5 box2d-py-2.3.8 gym-0.17.3 pyglet-1.5.0 pyvirtualdisplay-0.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# install required system dependencies\n",
    "sudo yum install -y xorg-x11-server-Xvfb.x86_64 xorg-x11-utils.x86_64\n",
    "\n",
    "# install required python dependencies (might need to install additional gym extras depending)\n",
    "pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGePTIPo6QC-"
   },
   "source": [
    "## Importing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q8_rmXAG6Fj6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os, copy\n",
    "from itertools import count\n",
    "import os\n",
    "\n",
    "\n",
    "# Gym is an OpenAI toolkit for RL\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfZ2Fd176XO0"
   },
   "source": [
    "## Setting Up stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmtvdYqE9GTI",
    "outputId": "d7f3c25f-242a-4362-dc0d-48cf81271a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":1001\n"
     ]
    }
   ],
   "source": [
    "# setting up the display\n",
    "import pyvirtualdisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                    size=(1400, 900))\n",
    "_ = _display.start()\n",
    "\n",
    "!echo $DISPLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FKt9tPMxFtN",
    "outputId": "cdfc9189-4761-400f-bbbc-c099ae7f225c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'x_pos_screen': 40, 'y_pos': 79}\n"
     ]
    }
   ],
   "source": [
    "# setting up environment and paramenters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "env = gym.make(\"SuperMarioBros-1-1-v0\")\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB6hXufezq-j"
   },
   "source": [
    "# Pre-process Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CKhy_dwhzuoV"
   },
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "\n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "env = FrameStack(env, num_stack=4)\n",
    "\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "state_shape = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGK2LkA96c1w"
   },
   "source": [
    "## The Actor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MyqpZzkI6fRY"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Actor, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        c, h, w = self.input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.linear1 = nn.Linear(3136, 512)\n",
    "        self.linear2 = nn.Linear(512, self.output_dim)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, state):\n",
    "        output = F.relu(self.conv1(state))\n",
    "        output = F.relu(self.conv2(output))\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = self.flatten(output)\n",
    "        output = F.relu(self.linear1(output))\n",
    "        output = self.linear2(output)\n",
    "        distribution = Categorical(F.softmax(output, dim=-1))\n",
    "        return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmjoMz706icq"
   },
   "source": [
    "## The Critic Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "95a7RbRy6nC8"
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        c, h, w = self.input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.linear1 = nn.Linear(3136, 512)\n",
    "        self.linear2 = nn.Linear(512, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, state):\n",
    "      output = F.relu(self.conv1(state))\n",
    "      output = F.relu(self.conv2(output))\n",
    "      output = F.relu(self.conv3(output))\n",
    "      output = self.flatten(output)\n",
    "      output = F.relu(self.linear1(output))\n",
    "      value = self.linear2(output)\n",
    "      return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxxjNC0c61Fn"
   },
   "source": [
    "## Compute returns \n",
    "\n",
    "It takes in rewards and computes the return for a certain episode/state using the discount factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O9T872Wj7B1Y"
   },
   "outputs": [],
   "source": [
    "def compute_returns(next_value, rewards, masks, gamma=0.99):\n",
    "    R = next_value\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        R = rewards[step] + gamma * R * masks[step]\n",
    "        returns.insert(0, R)\n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olWBVGEiQoVs"
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7_1iv9wdQqwT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "\n",
    "    def record(self, episode):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_rewards\", \"ep_lengths\"]:\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"))\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyoh7GaM7Z9x"
   },
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1frcB9wuOAKc"
   },
   "source": [
    "## Initializing display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2pWd9tTOC6c",
    "outputId": "369f7747-6a33-4c4b-fcc2-de7d702d914a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":1005\n"
     ]
    }
   ],
   "source": [
    "import pyvirtualdisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                    size=(1400, 900))\n",
    "_ = _display.start()\n",
    "\n",
    "!echo $DISPLAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-25HnJPPON4-"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7KAROqIK9X-",
    "outputId": "4963e076-5dac-40d6-fad5-46aeb57aee6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Reward: 231.0\n",
      "Episode: 1, Reward: 751.0\n",
      "Episode: 2, Reward: 231.0\n",
      "Episode: 3, Reward: 231.0\n",
      "Episode: 4, Reward: 231.0\n",
      "Episode: 5, Reward: 635.0\n",
      "Episode: 6, Reward: 606.0\n",
      "Episode: 7, Reward: 587.0\n",
      "Episode: 8, Reward: 231.0\n",
      "Episode: 9, Reward: 705.0\n",
      "Episode: 10, Reward: 588.0\n",
      "Episode: 11, Reward: 231.0\n",
      "Episode: 12, Reward: 231.0\n",
      "Episode: 13, Reward: 1175.0\n",
      "Episode: 14, Reward: 231.0\n",
      "Episode: 15, Reward: 627.0\n",
      "Episode: 16, Reward: 620.0\n",
      "Episode: 17, Reward: 708.0\n",
      "Episode: 18, Reward: 775.0\n",
      "Episode: 19, Reward: 635.0\n",
      "Episode: 20, Reward: 231.0\n",
      "Episode: 21, Reward: 763.0\n",
      "Episode: 22, Reward: 231.0\n",
      "Episode: 23, Reward: 604.0\n",
      "Episode: 24, Reward: 588.0\n",
      "Episode: 25, Reward: 605.0\n",
      "Episode: 26, Reward: 223.0\n",
      "Episode: 27, Reward: 614.0\n",
      "Episode: 28, Reward: 796.0\n",
      "Episode: 29, Reward: 1000.0\n",
      "Episode: 30, Reward: 231.0\n",
      "Episode: 31, Reward: 769.0\n",
      "Episode: 32, Reward: 800.0\n",
      "Episode: 33, Reward: 965.0\n",
      "Episode: 34, Reward: 636.0\n",
      "Episode: 35, Reward: 231.0\n",
      "Episode: 36, Reward: 751.0\n",
      "Episode: 37, Reward: 625.0\n",
      "Episode: 38, Reward: 626.0\n",
      "Episode: 39, Reward: 592.0\n",
      "Episode: 40, Reward: 217.0\n",
      "Episode: 41, Reward: 231.0\n",
      "Episode: 42, Reward: 584.0\n",
      "Episode: 43, Reward: 991.0\n",
      "Episode: 44, Reward: 780.0\n",
      "Episode: 45, Reward: 222.0\n",
      "Episode: 46, Reward: 600.0\n",
      "Episode: 47, Reward: 597.0\n",
      "Episode: 48, Reward: 218.0\n",
      "Episode: 49, Reward: 612.0\n",
      "Episode: 50, Reward: 1106.0\n",
      "Episode: 51, Reward: 634.0\n",
      "Episode: 52, Reward: 618.0\n",
      "Episode: 53, Reward: 231.0\n",
      "Episode: 54, Reward: 231.0\n",
      "Episode: 55, Reward: 989.0\n",
      "Episode: 56, Reward: 231.0\n",
      "Episode: 57, Reward: 231.0\n",
      "Episode: 58, Reward: 583.0\n",
      "Episode: 59, Reward: 617.0\n",
      "Episode: 60, Reward: 635.0\n",
      "Episode: 61, Reward: 988.0\n",
      "Episode: 62, Reward: 231.0\n",
      "Episode: 63, Reward: 701.0\n",
      "Episode: 64, Reward: 806.0\n",
      "Episode: 65, Reward: 723.0\n",
      "Episode: 66, Reward: 611.0\n",
      "Episode: 67, Reward: 231.0\n",
      "Episode: 68, Reward: 692.0\n",
      "Episode: 69, Reward: 1110.0\n",
      "Episode: 70, Reward: 626.0\n",
      "Episode: 71, Reward: 231.0\n",
      "Episode: 72, Reward: 626.0\n",
      "Episode: 73, Reward: 231.0\n",
      "Episode: 74, Reward: 1026.0\n",
      "Episode: 75, Reward: 749.0\n",
      "Episode: 76, Reward: 636.0\n",
      "Episode: 77, Reward: 231.0\n",
      "Episode: 78, Reward: 223.0\n",
      "Episode: 79, Reward: 222.0\n",
      "Episode: 80, Reward: 1783.0\n",
      "Episode: 81, Reward: 783.0\n",
      "Episode: 82, Reward: 1041.0\n",
      "Episode: 83, Reward: 1001.0\n",
      "Episode: 84, Reward: 231.0\n",
      "Episode: 85, Reward: 742.0\n",
      "Episode: 86, Reward: 1002.0\n",
      "Episode: 87, Reward: 622.0\n",
      "Episode: 88, Reward: 807.0\n",
      "Episode: 89, Reward: 996.0\n",
      "Episode: 90, Reward: 626.0\n",
      "Episode: 91, Reward: 991.0\n",
      "Episode: 92, Reward: 231.0\n",
      "Episode: 93, Reward: 223.0\n",
      "Episode: 94, Reward: 223.0\n",
      "Episode: 95, Reward: 994.0\n",
      "Episode: 96, Reward: 231.0\n",
      "Episode: 97, Reward: 619.0\n",
      "Episode: 98, Reward: 1289.0\n",
      "Episode: 99, Reward: 226.0\n",
      "Episode: 100, Reward: 1288.0\n",
      "Episode: 101, Reward: 626.0\n",
      "Episode: 102, Reward: 222.0\n",
      "Episode: 103, Reward: 1001.0\n",
      "Episode: 104, Reward: 711.0\n",
      "Episode: 105, Reward: 1262.0\n",
      "Episode: 106, Reward: 231.0\n",
      "Episode: 107, Reward: 713.0\n",
      "Episode: 108, Reward: 1255.0\n",
      "Episode: 109, Reward: 737.0\n",
      "Episode: 110, Reward: 731.0\n",
      "Episode: 111, Reward: 638.0\n",
      "Episode: 112, Reward: 705.0\n",
      "Episode: 113, Reward: 1043.0\n",
      "Episode: 114, Reward: 729.0\n",
      "Episode: 115, Reward: 231.0\n",
      "Episode: 116, Reward: 231.0\n",
      "Episode: 117, Reward: 757.0\n",
      "Episode: 118, Reward: 585.0\n",
      "Episode: 119, Reward: 1303.0\n",
      "Episode: 120, Reward: 769.0\n",
      "Episode: 121, Reward: 1005.0\n",
      "Episode: 122, Reward: 674.0\n",
      "Episode: 123, Reward: 767.0\n",
      "Episode: 124, Reward: 969.0\n",
      "Episode: 125, Reward: 223.0\n",
      "Episode: 126, Reward: 223.0\n",
      "Episode: 127, Reward: 634.0\n",
      "Episode: 128, Reward: 1013.0\n",
      "Episode: 129, Reward: 610.0\n",
      "Episode: 130, Reward: 1311.0\n",
      "Episode: 131, Reward: 218.0\n",
      "Episode: 132, Reward: 589.0\n",
      "Episode: 133, Reward: 597.0\n",
      "Episode: 134, Reward: 575.0\n",
      "Episode: 135, Reward: 693.0\n",
      "Episode: 136, Reward: 231.0\n",
      "Episode: 137, Reward: 613.0\n",
      "Episode: 138, Reward: 584.0\n",
      "Episode: 139, Reward: 633.0\n",
      "Episode: 140, Reward: 751.0\n",
      "Episode: 141, Reward: 226.0\n",
      "Episode: 142, Reward: 618.0\n",
      "Episode: 143, Reward: 231.0\n",
      "Episode: 144, Reward: 231.0\n",
      "Episode: 145, Reward: 231.0\n",
      "Episode: 146, Reward: 762.0\n",
      "Episode: 147, Reward: 602.0\n",
      "Episode: 148, Reward: 231.0\n",
      "Episode: 149, Reward: 618.0\n",
      "Episode: 150, Reward: 587.0\n",
      "Episode: 151, Reward: 222.0\n",
      "Episode: 152, Reward: 734.0\n",
      "Episode: 153, Reward: 787.0\n",
      "Episode: 154, Reward: 231.0\n",
      "Episode: 155, Reward: 231.0\n",
      "Episode: 156, Reward: 704.0\n",
      "Episode: 157, Reward: 601.0\n",
      "Episode: 158, Reward: 608.0\n",
      "Episode: 159, Reward: 614.0\n",
      "Episode: 160, Reward: 635.0\n",
      "Episode: 161, Reward: 657.0\n",
      "Episode: 162, Reward: 635.0\n",
      "Episode: 163, Reward: 636.0\n",
      "Episode: 164, Reward: 626.0\n",
      "Episode: 165, Reward: 614.0\n",
      "Episode: 166, Reward: 231.0\n",
      "Episode: 167, Reward: 635.0\n",
      "Episode: 168, Reward: 636.0\n",
      "Episode: 169, Reward: 618.0\n",
      "Episode: 170, Reward: 226.0\n",
      "Episode: 171, Reward: 231.0\n",
      "Episode: 172, Reward: 785.0\n",
      "Episode: 173, Reward: 659.0\n",
      "Episode: 174, Reward: 215.0\n",
      "Episode: 175, Reward: 619.0\n",
      "Episode: 176, Reward: 578.0\n",
      "Episode: 177, Reward: 589.0\n",
      "Episode: 178, Reward: 599.0\n",
      "Episode: 179, Reward: 598.0\n",
      "Episode: 180, Reward: 734.0\n",
      "Episode: 181, Reward: 676.0\n",
      "Episode: 182, Reward: 231.0\n",
      "Episode: 183, Reward: 1005.0\n",
      "Episode: 184, Reward: 231.0\n",
      "Episode: 185, Reward: 1001.0\n",
      "Episode: 186, Reward: 609.0\n",
      "Episode: 187, Reward: 732.0\n",
      "Episode: 188, Reward: 730.0\n",
      "Episode: 189, Reward: 636.0\n",
      "Episode: 190, Reward: 734.0\n",
      "Episode: 191, Reward: 1029.0\n",
      "Episode: 192, Reward: 734.0\n",
      "Episode: 193, Reward: 1282.0\n",
      "Episode: 194, Reward: 587.0\n",
      "Episode: 195, Reward: 231.0\n",
      "Episode: 196, Reward: 626.0\n",
      "Episode: 197, Reward: 795.0\n",
      "Episode: 198, Reward: 1277.0\n",
      "Episode: 199, Reward: 775.0\n",
      "Episode: 200, Reward: 231.0\n",
      "Episode: 201, Reward: 231.0\n",
      "Episode: 202, Reward: 628.0\n",
      "Episode: 203, Reward: 783.0\n",
      "Episode: 204, Reward: 605.0\n",
      "Episode: 205, Reward: 634.0\n",
      "Episode: 206, Reward: 636.0\n",
      "Episode: 207, Reward: 611.0\n",
      "Episode: 208, Reward: 623.0\n",
      "Episode: 209, Reward: 1785.0\n",
      "Episode: 210, Reward: 626.0\n",
      "Episode: 211, Reward: 584.0\n",
      "Episode: 212, Reward: 933.0\n",
      "Episode: 213, Reward: 741.0\n",
      "Episode: 214, Reward: 625.0\n",
      "Episode: 215, Reward: 618.0\n",
      "Episode: 216, Reward: 616.0\n",
      "Episode: 217, Reward: 1067.0\n",
      "Episode: 218, Reward: 635.0\n",
      "Episode: 219, Reward: 1549.0\n",
      "Episode: 220, Reward: 991.0\n",
      "Episode: 221, Reward: 785.0\n",
      "Episode: 222, Reward: 755.0\n",
      "Episode: 223, Reward: 806.0\n",
      "Episode: 224, Reward: 226.0\n",
      "Episode: 225, Reward: 942.0\n",
      "Episode: 226, Reward: 925.0\n",
      "Episode: 227, Reward: 694.0\n",
      "Episode: 228, Reward: 600.0\n",
      "Episode: 229, Reward: 922.0\n",
      "Episode: 230, Reward: 992.0\n",
      "Episode: 231, Reward: 618.0\n",
      "Episode: 232, Reward: 1024.0\n",
      "Episode: 233, Reward: 633.0\n",
      "Episode: 234, Reward: 609.0\n",
      "Episode: 235, Reward: 636.0\n",
      "Episode: 236, Reward: 596.0\n",
      "Episode: 237, Reward: 231.0\n",
      "Episode: 238, Reward: 605.0\n",
      "Episode: 239, Reward: 605.0\n",
      "Episode: 240, Reward: 773.0\n",
      "Episode: 241, Reward: 231.0\n",
      "Episode: 242, Reward: 607.0\n",
      "Episode: 243, Reward: 231.0\n",
      "Episode: 244, Reward: 999.0\n",
      "Episode: 245, Reward: 610.0\n",
      "Episode: 246, Reward: 231.0\n",
      "Episode: 247, Reward: 1012.0\n",
      "Episode: 248, Reward: 231.0\n",
      "Episode: 249, Reward: 738.0\n",
      "Episode: 250, Reward: 1232.0\n",
      "Episode: 251, Reward: 1198.0\n",
      "Episode: 252, Reward: 614.0\n",
      "Episode: 253, Reward: 674.0\n",
      "Episode: 254, Reward: 231.0\n",
      "Episode: 255, Reward: 633.0\n",
      "Episode: 256, Reward: 1008.0\n",
      "Episode: 257, Reward: 992.0\n",
      "Episode: 258, Reward: 231.0\n",
      "Episode: 259, Reward: 800.0\n",
      "Episode: 260, Reward: 231.0\n",
      "Episode: 261, Reward: 766.0\n",
      "Episode: 262, Reward: 708.0\n",
      "Episode: 263, Reward: 715.0\n",
      "Episode: 264, Reward: 590.0\n",
      "Episode: 265, Reward: 218.0\n",
      "Episode: 266, Reward: 606.0\n",
      "Episode: 267, Reward: 616.0\n",
      "Episode: 268, Reward: 915.0\n",
      "Episode: 269, Reward: 231.0\n",
      "Episode: 270, Reward: 223.0\n",
      "Episode: 271, Reward: 618.0\n",
      "Episode: 272, Reward: 231.0\n",
      "Episode: 273, Reward: 626.0\n",
      "Episode: 274, Reward: 231.0\n",
      "Episode: 275, Reward: 791.0\n",
      "Episode: 276, Reward: 611.0\n",
      "Episode: 277, Reward: 619.0\n",
      "Episode: 278, Reward: 231.0\n",
      "Episode: 279, Reward: 792.0\n",
      "Episode: 280, Reward: 231.0\n",
      "Episode: 281, Reward: 231.0\n",
      "Episode: 282, Reward: 231.0\n",
      "Episode: 283, Reward: 804.0\n",
      "Episode: 284, Reward: 1047.0\n",
      "Episode: 285, Reward: 1289.0\n",
      "Episode: 286, Reward: 620.0\n",
      "Episode: 287, Reward: 616.0\n",
      "Episode: 288, Reward: 231.0\n",
      "Episode: 289, Reward: 1245.0\n",
      "Episode: 290, Reward: 619.0\n",
      "Episode: 291, Reward: 231.0\n",
      "Episode: 292, Reward: 1287.0\n",
      "Episode: 293, Reward: 1023.0\n",
      "Episode: 294, Reward: 1014.0\n",
      "Episode: 295, Reward: 231.0\n",
      "Episode: 296, Reward: 753.0\n",
      "Episode: 297, Reward: 231.0\n",
      "Episode: 298, Reward: 705.0\n",
      "Episode: 299, Reward: 231.0\n",
      "Episode: 300, Reward: 231.0\n",
      "Episode: 301, Reward: 581.0\n",
      "Episode: 302, Reward: 601.0\n",
      "Episode: 303, Reward: 1005.0\n",
      "Episode: 304, Reward: 231.0\n",
      "Episode: 305, Reward: 231.0\n",
      "Episode: 306, Reward: 628.0\n",
      "Episode: 307, Reward: 618.0\n",
      "Episode: 308, Reward: 614.0\n",
      "Episode: 309, Reward: 1314.0\n",
      "Episode: 310, Reward: 231.0\n",
      "Episode: 311, Reward: 1400.0\n",
      "Episode: 312, Reward: 231.0\n",
      "Episode: 313, Reward: 619.0\n",
      "Episode: 314, Reward: 231.0\n",
      "Episode: 315, Reward: 746.0\n",
      "Episode: 316, Reward: 231.0\n",
      "Episode: 317, Reward: 231.0\n",
      "Episode: 318, Reward: 231.0\n",
      "Episode: 319, Reward: 231.0\n",
      "Episode: 320, Reward: 231.0\n",
      "Episode: 321, Reward: 231.0\n",
      "Episode: 322, Reward: 231.0\n",
      "Episode: 323, Reward: 231.0\n",
      "Episode: 324, Reward: 231.0\n",
      "Episode: 325, Reward: 231.0\n",
      "Episode: 326, Reward: 231.0\n",
      "Episode: 327, Reward: 231.0\n",
      "Episode: 328, Reward: 231.0\n",
      "Episode: 329, Reward: 231.0\n",
      "Episode: 330, Reward: 231.0\n",
      "Episode: 331, Reward: 231.0\n",
      "Episode: 332, Reward: 253.0\n",
      "Episode: 333, Reward: 231.0\n",
      "Episode: 334, Reward: 231.0\n",
      "Episode: 335, Reward: 231.0\n",
      "Episode: 336, Reward: 231.0\n",
      "Episode: 337, Reward: 231.0\n",
      "Episode: 338, Reward: 231.0\n",
      "Episode: 339, Reward: 231.0\n",
      "Episode: 340, Reward: 231.0\n",
      "Episode: 341, Reward: 231.0\n",
      "Episode: 342, Reward: 231.0\n",
      "Episode: 343, Reward: 231.0\n",
      "Episode: 344, Reward: 231.0\n",
      "Episode: 345, Reward: 231.0\n",
      "Episode: 346, Reward: 231.0\n",
      "Episode: 347, Reward: 231.0\n",
      "Episode: 348, Reward: 231.0\n",
      "Episode: 349, Reward: 969.0\n",
      "Episode: 350, Reward: 231.0\n",
      "Episode: 351, Reward: 231.0\n",
      "Episode: 352, Reward: 231.0\n",
      "Episode: 353, Reward: 231.0\n",
      "Episode: 354, Reward: 231.0\n",
      "Episode: 355, Reward: 231.0\n",
      "Episode: 356, Reward: 1320.0\n",
      "Episode: 357, Reward: 588.0\n",
      "Episode: 358, Reward: 231.0\n",
      "Episode: 359, Reward: 231.0\n",
      "Episode: 360, Reward: 231.0\n",
      "Episode: 361, Reward: 231.0\n",
      "Episode: 362, Reward: 619.0\n",
      "Episode: 363, Reward: 231.0\n",
      "Episode: 364, Reward: 231.0\n",
      "Episode: 365, Reward: 223.0\n",
      "Episode: 366, Reward: 231.0\n",
      "Episode: 367, Reward: 733.0\n",
      "Episode: 368, Reward: 231.0\n",
      "Episode: 369, Reward: 1039.0\n",
      "Episode: 370, Reward: 755.0\n",
      "Episode: 371, Reward: 1007.0\n",
      "Episode: 372, Reward: 231.0\n",
      "Episode: 373, Reward: 618.0\n",
      "Episode: 374, Reward: 231.0\n",
      "Episode: 375, Reward: 620.0\n",
      "Episode: 376, Reward: 609.0\n",
      "Episode: 377, Reward: 790.0\n",
      "Episode: 378, Reward: 231.0\n",
      "Episode: 379, Reward: 1311.0\n",
      "Episode: 380, Reward: 750.0\n",
      "Episode: 381, Reward: 963.0\n",
      "Episode: 382, Reward: 701.0\n",
      "Episode: 383, Reward: 709.0\n",
      "Episode: 384, Reward: 636.0\n",
      "Episode: 385, Reward: 1031.0\n",
      "Episode: 386, Reward: 1273.0\n",
      "Episode: 387, Reward: 1036.0\n",
      "Episode: 388, Reward: 231.0\n",
      "Episode: 389, Reward: 809.0\n",
      "Episode: 390, Reward: 785.0\n",
      "Episode: 391, Reward: 704.0\n",
      "Episode: 392, Reward: 602.0\n",
      "Episode: 393, Reward: 231.0\n",
      "Episode: 394, Reward: 231.0\n",
      "Episode: 395, Reward: 605.0\n",
      "Episode: 396, Reward: 618.0\n",
      "Episode: 397, Reward: 614.0\n",
      "Episode: 398, Reward: 231.0\n",
      "Episode: 399, Reward: 231.0\n",
      "Episode: 400, Reward: 223.0\n",
      "Episode: 401, Reward: 1023.0\n",
      "Episode: 402, Reward: 588.0\n",
      "Episode: 403, Reward: 614.0\n",
      "Episode: 404, Reward: 1401.0\n",
      "Episode: 405, Reward: 1040.0\n",
      "Episode: 406, Reward: 1322.0\n",
      "Episode: 407, Reward: 618.0\n",
      "Episode: 408, Reward: 1040.0\n",
      "Episode: 409, Reward: 619.0\n",
      "Episode: 410, Reward: 1119.0\n",
      "Episode: 411, Reward: 231.0\n",
      "Episode: 412, Reward: 1046.0\n",
      "Episode: 413, Reward: 231.0\n",
      "Episode: 414, Reward: 231.0\n",
      "Episode: 415, Reward: 231.0\n",
      "Episode: 416, Reward: 231.0\n",
      "Episode: 417, Reward: 1034.0\n",
      "Episode: 418, Reward: 1126.0\n",
      "Episode: 419, Reward: 1311.0\n",
      "Episode: 420, Reward: 1031.0\n",
      "Episode: 421, Reward: 1312.0\n",
      "Episode: 422, Reward: 1298.0\n",
      "Episode: 423, Reward: 753.0\n",
      "Episode: 424, Reward: 1041.0\n",
      "Episode: 425, Reward: 633.0\n",
      "Episode: 426, Reward: 1303.0\n",
      "Episode: 427, Reward: 586.0\n",
      "Episode: 428, Reward: 231.0\n",
      "Episode: 429, Reward: 798.0\n",
      "Episode: 430, Reward: 627.0\n",
      "Episode: 431, Reward: 802.0\n",
      "Episode: 432, Reward: 231.0\n",
      "Episode: 433, Reward: 595.0\n",
      "Episode: 434, Reward: 226.0\n",
      "Episode: 435, Reward: 733.0\n",
      "Episode: 436, Reward: 620.0\n",
      "Episode: 437, Reward: 231.0\n",
      "Episode: 438, Reward: 1321.0\n",
      "Episode: 439, Reward: 609.0\n",
      "Episode: 440, Reward: 217.0\n",
      "Episode: 441, Reward: 1036.0\n",
      "Episode: 442, Reward: 1020.0\n",
      "Episode: 443, Reward: 1296.0\n",
      "Episode: 444, Reward: 1010.0\n",
      "Episode: 445, Reward: 1024.0\n",
      "Episode: 446, Reward: 810.0\n",
      "Episode: 447, Reward: 750.0\n",
      "Episode: 448, Reward: 1023.0\n",
      "Episode: 449, Reward: 599.0\n",
      "Episode: 450, Reward: 704.0\n",
      "Episode: 451, Reward: 231.0\n",
      "Episode: 452, Reward: 608.0\n",
      "Episode: 453, Reward: 635.0\n",
      "Episode: 454, Reward: 1303.0\n",
      "Episode: 455, Reward: 1034.0\n",
      "Episode: 456, Reward: 636.0\n",
      "Episode: 457, Reward: 713.0\n",
      "Episode: 458, Reward: 626.0\n",
      "Episode: 459, Reward: 635.0\n",
      "Episode: 460, Reward: 589.0\n",
      "Episode: 461, Reward: 605.0\n",
      "Episode: 462, Reward: 223.0\n",
      "Episode: 463, Reward: 231.0\n",
      "Episode: 464, Reward: 996.0\n",
      "Episode: 465, Reward: 1031.0\n",
      "Episode: 466, Reward: 740.0\n",
      "Episode: 467, Reward: 1045.0\n",
      "Episode: 468, Reward: 226.0\n",
      "Episode: 469, Reward: 231.0\n",
      "Episode: 470, Reward: 609.0\n",
      "Episode: 471, Reward: 1016.0\n",
      "Episode: 472, Reward: 627.0\n",
      "Episode: 473, Reward: 1038.0\n",
      "Episode: 474, Reward: 1035.0\n",
      "Episode: 475, Reward: 635.0\n",
      "Episode: 476, Reward: 620.0\n",
      "Episode: 477, Reward: 611.0\n",
      "Episode: 478, Reward: 1035.0\n",
      "Episode: 479, Reward: 593.0\n",
      "Episode: 480, Reward: 231.0\n",
      "Episode: 481, Reward: 2328.0\n",
      "Episode: 482, Reward: 729.0\n",
      "Episode: 483, Reward: 1025.0\n",
      "Episode: 484, Reward: 628.0\n",
      "Episode: 485, Reward: 618.0\n",
      "Episode: 486, Reward: 217.0\n",
      "Episode: 487, Reward: 1395.0\n",
      "Episode: 488, Reward: 634.0\n",
      "Episode: 489, Reward: 743.0\n",
      "Episode: 490, Reward: 615.0\n",
      "Episode: 491, Reward: 1298.0\n",
      "Episode: 492, Reward: 707.0\n",
      "Episode: 493, Reward: 604.0\n",
      "Episode: 494, Reward: 750.0\n",
      "Episode: 495, Reward: 1024.0\n",
      "Episode: 496, Reward: 807.0\n",
      "Episode: 497, Reward: 626.0\n",
      "Episode: 498, Reward: 231.0\n",
      "Episode: 499, Reward: 746.0\n"
     ]
    }
   ],
   "source": [
    "save_dir = Path(\"mario_a2c_checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "actor = Actor(input_dim=(4, 84, 84), output_dim=env.action_space.n).to(device)\n",
    "critic = Critic(input_dim=(4, 84, 84), output_dim=env.action_space.n).to(device)\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "save_every = 5\n",
    "log_every = 2\n",
    "\n",
    "optimizerA = optim.Adam(actor.parameters(), lr=0.00025)\n",
    "optimizerC = optim.Adam(critic.parameters(), lr=0.00025)\n",
    "\n",
    "for e in range(1, episodes + 1):\n",
    "    state = env.reset()\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    entropy = 0\n",
    "\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "    episode_rewards = 0\n",
    "\n",
    "    for i in count():\n",
    "\n",
    "        # Added\n",
    "        img.set_data(env.render(mode='rgb_array'))\n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        state = state.__array__()\n",
    "        state = torch.tensor(state).to(device)\n",
    "        state = state.unsqueeze(0)\n",
    "        dist = actor(state)\n",
    "        value = critic(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "\n",
    "        next_state, reward, done, info = env.step(int(action))\n",
    "\n",
    "        logger.log_step(reward)\n",
    "        episode_rewards += reward\n",
    "\n",
    "        log_prob = dist.log_prob(action).unsqueeze(0)\n",
    "        entropy += dist.entropy().mean()\n",
    "\n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.tensor([reward], dtype=torch.float, device=device))\n",
    "        masks.append(torch.tensor([1-done], dtype=torch.float, device=device))\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done or info[\"flag_get\"]:\n",
    "            print(f'Episode: {e}, Reward: {episode_rewards}')\n",
    "            break\n",
    "    \n",
    "    logger.log_episode()\n",
    "\n",
    "    next_state = next_state.__array__()\n",
    "    next_state = torch.tensor(next_state).to(device)\n",
    "    next_state = next_state.unsqueeze(0)\n",
    "\n",
    "    next_value = critic(next_state)\n",
    "    returns = compute_returns(next_value, rewards, masks)\n",
    "\n",
    "    log_probs = torch.cat(log_probs)\n",
    "    returns = torch.cat(returns).detach()\n",
    "    values = torch.cat(values)\n",
    "\n",
    "    advantage = returns - values\n",
    "\n",
    "    actor_loss = -(log_probs * advantage.detach()).mean()\n",
    "    critic_loss = advantage.pow(2).mean()\n",
    "\n",
    "    optimizerA.zero_grad()\n",
    "    optimizerC.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    critic_loss.backward()\n",
    "    optimizerA.step()\n",
    "    optimizerC.step()\n",
    "\n",
    "    # if e % log_every == 0:\n",
    "    #     logger.record(episode=e)\n",
    "\n",
    "    if e % save_every == 0:\n",
    "        torch.save(actor, save_dir / f'actor_{e}.pkl')\n",
    "        torch.save(critic, save_dir / f'critic{e}.pkl')\n",
    "# ipythondisplay.clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPYDiHVBIZ+r0Nj61qpOyHG",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1QKnihasUHT-ODEJtZs9XP_Pwd90MSDV8",
   "name": "Advantage Actor Critic for Mario.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

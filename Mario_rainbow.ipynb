{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Mario_rainbow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nischal-p/cis-419-project/blob/main/Mario_rainbow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1RFWXdsefin"
      },
      "source": [
        "## Configurations for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzVQBrqpefit"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt install python-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install pyvirtualdisplay\n",
        "    !pip install gym\n",
        "    from pyvirtualdisplay import Display\n",
        "    \n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(400, 400))\n",
        "    dis.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZGyCWXci5Mj"
      },
      "source": [
        "#Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbkZSFhzi3_N",
        "outputId": "8608ba0f-b537-4720-bf79-f68af8d9bf87"
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install gym-super-mario-bros==7.3.0\n",
        "!sudo apt-get install fceux"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym-super-mario-bros==7.3.0 in /usr/local/lib/python3.7/dist-packages (7.3.0)\n",
            "Requirement already satisfied: nes-py>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from gym-super-mario-bros==7.3.0) (8.1.8)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.11,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.5.0)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.11,>=1.4.0->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fceux is already the newest version (2.2.2+dfsg0-1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddjinGGdjRYV"
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import random, datetime, os, copy\n",
        "\n",
        "# Gym is an OpenAI toolkit for RL\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "# NES Emulator for OpenAI Gym\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "\n",
        "# Super Mario environment for OpenAI Gym\n",
        "import gym_super_mario_bros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-cgf-K_jDlt",
        "outputId": "98c6766e-6608-4ebe-aa29-549f0658503e"
      },
      "source": [
        "# Initialize Super Mario environment\n",
        "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
        "\n",
        "# Limit the action-space to\n",
        "#   0. walk right\n",
        "#   1. jump right\n",
        "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
        "\n",
        "env.reset()\n",
        "next_state, reward, done, info = env.step(action=0)\n",
        "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 256, 3),\n",
            " 0,\n",
            " False,\n",
            " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'x_pos_screen': 40, 'y_pos': 79}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPmK5HLejeUZ"
      },
      "source": [
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, and sum reward\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for i in range(self._skip):\n",
        "            # Accumulate reward and repeat the same action\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "\n",
        "class GrayScaleObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs_shape = self.observation_space.shape[:2]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def permute_orientation(self, observation):\n",
        "        # permute [H, W, C] array to [C, H, W] tensor\n",
        "        observation = np.transpose(observation, (2, 0, 1))\n",
        "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
        "        return observation\n",
        "\n",
        "    def observation(self, observation):\n",
        "        observation = self.permute_orientation(observation)\n",
        "        transform = T.Grayscale()\n",
        "        observation = transform(observation)\n",
        "        return observation\n",
        "\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        transforms = T.Compose(\n",
        "            [T.Resize(self.shape), T.Normalize(0, 255)]\n",
        "        )\n",
        "        observation = transforms(observation).squeeze(0)\n",
        "        return observation\n",
        "\n",
        "\n",
        "# Apply Wrappers to environment\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "env = FrameStack(env, num_stack=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS7Fb05refiw"
      },
      "source": [
        "# 08. Rainbow\n",
        "\n",
        "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
        "\n",
        "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
        "\n",
        "1. DQN\n",
        "2. Double DQN\n",
        "3. Prioritized Experience Replay\n",
        "4. Dueling Network\n",
        "5. Noisy Network\n",
        "6. Categorical DQN\n",
        "7. N-step Learning\n",
        "\n",
        "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
        "\n",
        "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
        "\n",
        "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
        "\n",
        "1. Noisy Network <-> Dueling Network\n",
        "2. Dueling Network <-> Categorical DQN\n",
        "3. Categorical DQN <-> Double DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPKjevKyefix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a242a19-fa98-4fa0-9567-921189afb7d7"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import random\n",
        "from collections import deque\n",
        "from typing import Deque, Dict, List, Tuple\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# download segment tree module\n",
        "if IN_COLAB:\n",
        "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
        "\n",
        "from segment_tree import MinSegmentTree, SumSegmentTree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 07:39:21--  https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4283 (4.2K) [text/plain]\n",
            "Saving to: ‘segment_tree.py.1’\n",
            "\n",
            "\rsegment_tree.py.1     0%[                    ]       0  --.-KB/s               \rsegment_tree.py.1   100%[===================>]   4.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-07 07:39:21 (38.2 MB/s) - ‘segment_tree.py.1’ saved [4283/4283]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8O9YvCCefiz"
      },
      "source": [
        "## Replay buffer\n",
        "\n",
        "Same as the basic N-step buffer. \n",
        "\n",
        "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL6Dg5qXefi1"
      },
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        obs_dim: int, \n",
        "        size: int, \n",
        "        batch_size: int = 32, \n",
        "        n_step: int = 1, \n",
        "        gamma: float = 0.99\n",
        "    ):\n",
        "        self.obs_buf = np.zeros([size, obs_dim[0], obs_dim[1],obs_dim[2]], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size,  obs_dim[0], obs_dim[1],obs_dim[2]], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "        \n",
        "        # for N-step Learning\n",
        "        self.n_step_buffer = deque(maxlen=n_step)\n",
        "        self.n_step = n_step\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def store(\n",
        "        self, \n",
        "        obs: np.ndarray, \n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
        "        transition = (obs, act, rew, next_obs, done)\n",
        "        self.n_step_buffer.append(transition)\n",
        "\n",
        "        # single step transition is not ready\n",
        "        if len(self.n_step_buffer) < self.n_step:\n",
        "            return ()\n",
        "        \n",
        "        # make a n-step transition\n",
        "        rew, next_obs, done = self._get_n_step_info(\n",
        "            self.n_step_buffer, self.gamma\n",
        "        )\n",
        "        obs, act = self.n_step_buffer[0][:2]\n",
        "        \n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "        \n",
        "        return self.n_step_buffer[0]\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "\n",
        "        return dict(\n",
        "            obs=self.obs_buf[idxs],\n",
        "            next_obs=self.next_obs_buf[idxs],\n",
        "            acts=self.acts_buf[idxs],\n",
        "            rews=self.rews_buf[idxs],\n",
        "            done=self.done_buf[idxs],\n",
        "            # for N-step Learning\n",
        "            indices=idxs,\n",
        "        )\n",
        "    \n",
        "    def sample_batch_from_idxs(\n",
        "        self, idxs: np.ndarray\n",
        "    ) -> Dict[str, np.ndarray]:\n",
        "        # for N-step Learning\n",
        "        return dict(\n",
        "            obs=self.obs_buf[idxs],\n",
        "            next_obs=self.next_obs_buf[idxs],\n",
        "            acts=self.acts_buf[idxs],\n",
        "            rews=self.rews_buf[idxs],\n",
        "            done=self.done_buf[idxs],\n",
        "        )\n",
        "    \n",
        "    def _get_n_step_info(\n",
        "        self, n_step_buffer: Deque, gamma: float\n",
        "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
        "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
        "        # info of the last transition\n",
        "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
        "\n",
        "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
        "            r, n_o, d = transition[-3:]\n",
        "\n",
        "            rew = r + gamma * rew * (1 - d)\n",
        "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
        "\n",
        "        return rew, next_obs, done\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp3SuHArksm7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FXHdpBKefi9"
      },
      "source": [
        "## Prioritized replay Buffer\n",
        "\n",
        "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
        "\n",
        "(Please see *02.per.ipynb* for detailed description about PER.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKkeKywsefi-"
      },
      "source": [
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    \"\"\"Prioritized Replay buffer.\n",
        "    \n",
        "    Attributes:\n",
        "        max_priority (float): max priority\n",
        "        tree_ptr (int): next index of tree\n",
        "        alpha (float): alpha parameter for prioritized replay buffer\n",
        "        sum_tree (SumSegmentTree): sum tree for prior\n",
        "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self, \n",
        "        obs_dim: int, \n",
        "        size: int, \n",
        "        batch_size: int = 32, \n",
        "        alpha: float = 0.6,\n",
        "        n_step: int = 1, \n",
        "        gamma: float = 0.99,\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        assert alpha >= 0\n",
        "        \n",
        "        super(PrioritizedReplayBuffer, self).__init__(\n",
        "            obs_dim, size, batch_size, n_step, gamma\n",
        "        )\n",
        "        self.max_priority, self.tree_ptr = 1.0, 0\n",
        "        self.alpha = alpha\n",
        "        \n",
        "        # capacity must be positive and a power of 2.\n",
        "        tree_capacity = 1\n",
        "        while tree_capacity < self.max_size:\n",
        "            tree_capacity *= 2\n",
        "\n",
        "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
        "        self.min_tree = MinSegmentTree(tree_capacity)\n",
        "        \n",
        "    def store(\n",
        "        self, \n",
        "        obs: np.ndarray, \n",
        "        act: int, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
        "        \"\"\"Store experience and priority.\"\"\"\n",
        "        transition = super().store(obs, act, rew, next_obs, done)\n",
        "        \n",
        "        if transition:\n",
        "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
        "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
        "        \n",
        "        return transition\n",
        "\n",
        "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Sample a batch of experiences.\"\"\"\n",
        "        assert len(self) >= self.batch_size\n",
        "        assert beta > 0\n",
        "        \n",
        "        indices = self._sample_proportional()\n",
        "        \n",
        "        obs = self.obs_buf[indices]\n",
        "        next_obs = self.next_obs_buf[indices]\n",
        "        acts = self.acts_buf[indices]\n",
        "        rews = self.rews_buf[indices]\n",
        "        done = self.done_buf[indices]\n",
        "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
        "        \n",
        "        return dict(\n",
        "            obs=obs,\n",
        "            next_obs=next_obs,\n",
        "            acts=acts,\n",
        "            rews=rews,\n",
        "            done=done,\n",
        "            weights=weights,\n",
        "            indices=indices,\n",
        "        )\n",
        "        \n",
        "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
        "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
        "        assert len(indices) == len(priorities)\n",
        "\n",
        "        for idx, priority in zip(indices, priorities):\n",
        "            assert priority > 0\n",
        "            assert 0 <= idx < len(self)\n",
        "\n",
        "            self.sum_tree[idx] = priority ** self.alpha\n",
        "            self.min_tree[idx] = priority ** self.alpha\n",
        "\n",
        "            self.max_priority = max(self.max_priority, priority)\n",
        "            \n",
        "    def _sample_proportional(self) -> List[int]:\n",
        "        \"\"\"Sample indices based on proportions.\"\"\"\n",
        "        indices = []\n",
        "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
        "        segment = p_total / self.batch_size\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            a = segment * i\n",
        "            b = segment * (i + 1)\n",
        "            upperbound = random.uniform(a, b)\n",
        "            idx = self.sum_tree.retrieve(upperbound)\n",
        "            indices.append(idx)\n",
        "            \n",
        "        return indices\n",
        "    \n",
        "    def _calculate_weight(self, idx: int, beta: float):\n",
        "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
        "        # get max weight\n",
        "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
        "        max_weight = (p_min * len(self)) ** (-beta)\n",
        "        \n",
        "        # calculate weights\n",
        "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
        "        weight = (p_sample * len(self)) ** (-beta)\n",
        "        weight = weight / max_weight\n",
        "        \n",
        "        return weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSY7hkVoefjC"
      },
      "source": [
        "## Noisy Layer\n",
        "\n",
        "Please see *05.noisy_net.ipynb* for detailed description.\n",
        "\n",
        "**References:**\n",
        "\n",
        "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
        "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbc3IqgJefjD"
      },
      "source": [
        "class NoisyLinear(nn.Module):\n",
        "    \"\"\"Noisy linear module for NoisyNet.\n",
        "    \n",
        "    \n",
        "        \n",
        "    Attributes:\n",
        "        in_features (int): input size of linear module\n",
        "        out_features (int): output size of linear module\n",
        "        std_init (float): initial std value\n",
        "        weight_mu (nn.Parameter): mean value weight parameter\n",
        "        weight_sigma (nn.Parameter): std value weight parameter\n",
        "        bias_mu (nn.Parameter): mean value bias parameter\n",
        "        bias_sigma (nn.Parameter): std value bias parameter\n",
        "        \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_features: int, \n",
        "        out_features: int, \n",
        "        std_init: float = 0.5,\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(NoisyLinear, self).__init__()\n",
        "        \n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.std_init = std_init\n",
        "\n",
        "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.weight_sigma = nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features)\n",
        "        )\n",
        "        self.register_buffer(\n",
        "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
        "        )\n",
        "\n",
        "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
        "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
        "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
        "\n",
        "        self.reset_parameters()\n",
        "        self.reset_noise()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
        "        mu_range = 1 / math.sqrt(self.in_features)\n",
        "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.weight_sigma.data.fill_(\n",
        "            self.std_init / math.sqrt(self.in_features)\n",
        "        )\n",
        "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.bias_sigma.data.fill_(\n",
        "            self.std_init / math.sqrt(self.out_features)\n",
        "        )\n",
        "\n",
        "    def reset_noise(self):\n",
        "        \"\"\"Make new noise.\"\"\"\n",
        "        epsilon_in = self.scale_noise(self.in_features)\n",
        "        epsilon_out = self.scale_noise(self.out_features)\n",
        "\n",
        "        # outer product\n",
        "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
        "        self.bias_epsilon.copy_(epsilon_out)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\n",
        "        \n",
        "        We don't use separate statements on train / eval mode.\n",
        "        It doesn't show remarkable difference of performance.\n",
        "        \"\"\"\n",
        "        return F.linear(\n",
        "            x,\n",
        "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
        "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
        "        )\n",
        "    \n",
        "    @staticmethod\n",
        "    def scale_noise(size: int) -> torch.Tensor:\n",
        "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
        "        x = torch.randn(size)\n",
        "\n",
        "        return x.sign().mul(x.abs().sqrt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV0Q1cj3efjF"
      },
      "source": [
        "## NoisyNet + DuelingNet + Categorical DQN\n",
        "\n",
        "#### NoisyNet + DuelingNet\n",
        "\n",
        "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
        "\n",
        "#### DuelingNet + Categorical DQN\n",
        "\n",
        "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
        "\n",
        "```\n",
        "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
        "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
        "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
        "        \n",
        "        dist = F.softmax(q_atoms, dim=-1)\n",
        "```\n",
        "\n",
        "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCd7uFjqefjG"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_dim, \n",
        "        out_dim: int, \n",
        "        atom_size: int, \n",
        "        support: torch.Tensor\n",
        "    ):\n",
        "        \"\"\"Initialization.\"\"\"\n",
        "        super(Network, self).__init__()\n",
        "        \n",
        "        self.support = support\n",
        "        self.out_dim = out_dim\n",
        "        self.atom_size = atom_size\n",
        "        self.fc_input_dim = 3136;\n",
        "        c, h, w = in_dim\n",
        "        # set common feature layer\n",
        "        self.feature_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.advantage_stream = nn.Sequential(\n",
        "            NoisyLinear(self.fc_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            NoisyLinear(128, out_dim*atom_size)\n",
        "        )\n",
        "        self.value_stream = nn.Sequential(\n",
        "            NoisyLinear(self.fc_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            NoisyLinear(128, atom_size)\n",
        "        )\n",
        "\n",
        "        # set advantage layer\n",
        "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
        "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
        "\n",
        "        # set value layer\n",
        "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
        "        self.value_layer = NoisyLinear(128, atom_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        dist = self.dist(x)\n",
        "        q = torch.sum(dist * self.support, dim=2)\n",
        "        \n",
        "        return q\n",
        "    \n",
        "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Get distribution for atoms.\"\"\"\n",
        "        feature = self.feature_layer(x)\n",
        "        #adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
        "        #val_hid = F.relu(self.value_hidden_layer(feature))\n",
        "        feature = feature.view(feature.size(0), -1)\n",
        "        advantage = self.advantage_stream(feature).view(\n",
        "            -1, self.out_dim, self.atom_size\n",
        "        )\n",
        "        value = self.value_stream(feature).view(-1, 1, self.atom_size)\n",
        "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
        "        \n",
        "        dist = F.softmax(q_atoms, dim=-1)\n",
        "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
        "        \n",
        "        return dist\n",
        "    \n",
        "    def reset_noise(self):\n",
        "        \"\"\"Reset all noisy layers.\"\"\"\n",
        "        self.advantage_hidden_layer.reset_noise()\n",
        "        self.advantage_layer.reset_noise()\n",
        "        self.value_hidden_layer.reset_noise()\n",
        "        self.value_layer.reset_noise()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkuZxL5EefjI"
      },
      "source": [
        "## Rainbow Agent\n",
        "\n",
        "Here is a summary of DQNAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "| ---              | ---                                                  |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|compute_dqn_loss  | return dqn loss.                                     |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|target_hard_update| hard update from the local model to the target model.|\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|plot              | plot the training progresses.                        |\n",
        "\n",
        "#### Categorical DQN + Double DQN\n",
        "\n",
        "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
        "\n",
        "```\n",
        "        # Categorical DQN + Double DQN\n",
        "        # target_dqn is used when we don't employ double DQN\n",
        "        next_action = self.dqn(next_state).argmax(1)\n",
        "        next_dist = self.dqn_target.dist(next_state)\n",
        "        next_dist = next_dist[range(self.batch_size), next_action]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuk020BiefjM"
      },
      "source": [
        "class DQNAgent:\n",
        "    \"\"\"DQN Agent interacting with environment.\n",
        "    \n",
        "    Attribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
        "        batch_size (int): batch size for sampling\n",
        "        target_update (int): period for target model's hard update\n",
        "        gamma (float): discount factor\n",
        "        dqn (Network): model to train and select actions\n",
        "        dqn_target (Network): target model to update\n",
        "        optimizer (torch.optim): optimizer for training dqn\n",
        "        transition (list): transition information including \n",
        "                           state, action, reward, next_state, done\n",
        "        v_min (float): min value of support\n",
        "        v_max (float): max value of support\n",
        "        atom_size (int): the unit number of support\n",
        "        support (torch.Tensor): support for categorical dqn\n",
        "        use_n_step (bool): whether to use n_step memory\n",
        "        n_step (int): step number to calculate n-step td error\n",
        "        memory_n (ReplayBuffer): n-step replay buffer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        env: gym.Env,\n",
        "        memory_size: int,\n",
        "        batch_size: int,\n",
        "        target_update: int,\n",
        "        gamma: float = 0.99,\n",
        "        # PER parameters\n",
        "        alpha: float = 0.2,\n",
        "        beta: float = 0.6,\n",
        "        prior_eps: float = 1e-6,\n",
        "        # Categorical DQN parameters\n",
        "        v_min: float = 0.0,\n",
        "        v_max: float = 1000,\n",
        "        atom_size: int = 51,\n",
        "        # N-step Learning\n",
        "        n_step: int = 3,\n",
        "    ):\n",
        "        \"\"\"Initialization.\n",
        "        \n",
        "        Args:\n",
        "            env (gym.Env): openAI Gym environment\n",
        "            memory_size (int): length of memory\n",
        "            batch_size (int): batch size for sampling\n",
        "            target_update (int): period for target model's hard update\n",
        "            lr (float): learning rate\n",
        "            gamma (float): discount factor\n",
        "            alpha (float): determines how much prioritization is used\n",
        "            beta (float): determines how much importance sampling is used\n",
        "            prior_eps (float): guarantees every transition can be sampled\n",
        "            v_min (float): min value of support\n",
        "            v_max (float): max value of support\n",
        "            atom_size (int): the unit number of support\n",
        "            n_step (int): step number to calculate n-step td error\n",
        "        \"\"\"\n",
        "        obs_dim = [4,84,84]#env.observation_space.shape\n",
        "        action_dim = env.action_space.n\n",
        "        print(obs_dim)\n",
        "        self.env = env\n",
        "        self.batch_size = batch_size\n",
        "        self.target_update = target_update\n",
        "        self.gamma = gamma\n",
        "        # NoisyNet: All attributes related to epsilon are removed\n",
        "        \n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        print(self.device)\n",
        "        \n",
        "        # PER\n",
        "        # memory for 1-step Learning\n",
        "        self.beta = beta\n",
        "        self.prior_eps = prior_eps\n",
        "        self.memory = PrioritizedReplayBuffer(\n",
        "            obs_dim, memory_size, batch_size, alpha=alpha\n",
        "        )\n",
        "        \n",
        "        # memory for N-step Learning\n",
        "        self.use_n_step = True if n_step > 1 else False\n",
        "        if self.use_n_step:\n",
        "            self.n_step = n_step\n",
        "            self.memory_n = ReplayBuffer(\n",
        "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
        "            )\n",
        "            \n",
        "        # Categorical DQN parameters\n",
        "        self.v_min = v_min\n",
        "        self.v_max = v_max\n",
        "        self.atom_size = atom_size\n",
        "        self.support = torch.linspace(\n",
        "            self.v_min, self.v_max, self.atom_size\n",
        "        ).to(self.device)\n",
        "\n",
        "        # networks: dqn, dqn_target\n",
        "        self.dqn = Network(\n",
        "            obs_dim, action_dim, self.atom_size, self.support\n",
        "        ).to(self.device)\n",
        "        self.dqn_target = Network(\n",
        "            obs_dim, action_dim, self.atom_size, self.support\n",
        "        ).to(self.device)\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "        self.dqn_target.eval()\n",
        "        \n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
        "\n",
        "        # transition to store in memory\n",
        "        self.transition = list()\n",
        "        \n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "\n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        # NoisyNet: no epsilon greedy action selection\n",
        "        state = state.__array__()\n",
        "        state =  torch.Tensor(state).unsqueeze(0)\n",
        "        #print(state.shape)\n",
        "        selected_action = self.dqn(\n",
        "           state.to(self.device)\n",
        "        )\n",
        "        #print(selected_action)\n",
        "        selected_action = selected_action.argmax()\n",
        "        \n",
        "        selected_action = selected_action.detach().cpu().numpy()\n",
        "        \n",
        "        if not self.is_test:\n",
        "            self.transition = [state, selected_action]\n",
        "        #print(selected_action)\n",
        "        return selected_action\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, done, _ = self.env.step(action)\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition += [reward, next_state, done]\n",
        "            \n",
        "            # N-step transition\n",
        "            if self.use_n_step:\n",
        "                one_step_transition = self.memory_n.store(*self.transition)\n",
        "            # 1-step transition\n",
        "            else:\n",
        "                one_step_transition = self.transition\n",
        "\n",
        "            # add a single step transition\n",
        "            if one_step_transition:\n",
        "                self.memory.store(*one_step_transition)\n",
        "    \n",
        "        return next_state, reward, done\n",
        "\n",
        "    def update_model(self) -> torch.Tensor:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        # PER needs beta to calculate weights\n",
        "        samples = self.memory.sample_batch(self.beta)\n",
        "        weights = torch.FloatTensor(\n",
        "            samples[\"weights\"].reshape(-1, 1)\n",
        "        ).to(self.device)\n",
        "        indices = samples[\"indices\"]\n",
        "        \n",
        "        # 1-step Learning loss\n",
        "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
        "        \n",
        "        # PER: importance sampling before average\n",
        "        loss = torch.mean(elementwise_loss * weights)\n",
        "        \n",
        "        # N-step Learning loss\n",
        "        # we are gonna combine 1-step loss and n-step loss so as to\n",
        "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
        "        if self.use_n_step:\n",
        "            gamma = self.gamma ** self.n_step\n",
        "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
        "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
        "            elementwise_loss += elementwise_loss_n_loss\n",
        "            \n",
        "            # PER: importance sampling before average\n",
        "            loss = torch.mean(elementwise_loss * weights)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
        "        self.optimizer.step()\n",
        "        \n",
        "        # PER: update priorities\n",
        "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
        "        new_priorities = loss_for_prior + self.prior_eps\n",
        "        self.memory.update_priorities(indices, new_priorities)\n",
        "        \n",
        "        # NoisyNet: reset noise\n",
        "        self.dqn.reset_noise()\n",
        "        self.dqn_target.reset_noise()\n",
        "\n",
        "        return loss.item()\n",
        "        \n",
        "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "        \n",
        "        state = self.env.reset()\n",
        "        update_cnt = 0\n",
        "        losses = []\n",
        "        scores = []\n",
        "        score = 0\n",
        "        episode = 0;\n",
        "\n",
        "        \n",
        "        for frame_idx in range(1, num_frames + 1):\n",
        "            state = state.__array__()\n",
        "            #print(\"hello\")\n",
        "            action = self.select_action(state).item()\n",
        "            #print(type(action))\n",
        "            next_state, reward, done = self.step(action)\n",
        "            next_state = next_state.__array__()\n",
        "\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            \n",
        "            # NoisyNet: removed decrease of epsilon\n",
        "            \n",
        "            # PER: increase beta\n",
        "            fraction = min(frame_idx / num_frames, 1.0)\n",
        "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
        "\n",
        "            # if episode ends\n",
        "            if done:\n",
        "                \n",
        "                episode = episode +1;\n",
        "                print(episode);\n",
        "                if(episode % 1000 == 0):\n",
        "                    #print(\"done\")\n",
        "                    torch.save( self.dqn.state_dict() , '/content/gdrive/Shareddrives/CIS 519 Project/Rainbow_savefiles/episodes{}.pth'.format(episode) )\n",
        "                state = self.env.reset()\n",
        "                scores.append(score)\n",
        "                score = 0\n",
        "\n",
        "            # if training is ready\n",
        "            if len(self.memory) >= self.batch_size:\n",
        "                loss = self.update_model()\n",
        "                losses.append(loss)\n",
        "                update_cnt += 1\n",
        "                \n",
        "                # if hard update is needed\n",
        "                if update_cnt % self.target_update == 0:\n",
        "                    self._target_hard_update()\n",
        "\n",
        "            # plotting\n",
        "            if frame_idx % plotting_interval == 0:\n",
        "                self._plot(frame_idx, scores, losses)\n",
        "                pass;\n",
        "                \n",
        "        self.env.close()\n",
        "                \n",
        "    def test(self) -> List[np.ndarray]:\n",
        "        \"\"\"Test the agent.\"\"\"\n",
        "        self.is_test = True\n",
        "        \n",
        "        state = self.env.reset()\n",
        "        done = False\n",
        "        score = 0\n",
        "        \n",
        "        frames = []\n",
        "        while not done:\n",
        "            frames.append(self.env.render(mode=\"rgb_array\"))\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "        \n",
        "        print(\"score: \", score)\n",
        "        self.env.close()\n",
        "        \n",
        "        return frames\n",
        "\n",
        "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
        "        \"\"\"Return categorical dqn loss.\"\"\"\n",
        "        device = self.device  # for shortening the following lines\n",
        "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
        "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "        \n",
        "        # Categorical DQN algorithm\n",
        "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Double DQN\n",
        "            next_action = self.dqn(next_state).argmax(1)\n",
        "            next_dist = self.dqn_target.dist(next_state)\n",
        "            next_dist = next_dist[range(self.batch_size), next_action]\n",
        "\n",
        "            t_z = reward + (1 - done) * gamma * self.support\n",
        "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
        "            b = (t_z - self.v_min) / delta_z\n",
        "            l = b.floor().long()\n",
        "            u = b.ceil().long()\n",
        "\n",
        "            offset = (\n",
        "                torch.linspace(\n",
        "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
        "                ).long()\n",
        "                .unsqueeze(1)\n",
        "                .expand(self.batch_size, self.atom_size)\n",
        "                .to(self.device)\n",
        "            )\n",
        "\n",
        "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
        "            proj_dist.view(-1).index_add_(\n",
        "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
        "            )\n",
        "            proj_dist.view(-1).index_add_(\n",
        "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
        "            )\n",
        "\n",
        "        dist = self.dqn.dist(state)\n",
        "        log_p = torch.log(dist[range(self.batch_size), action])\n",
        "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
        "\n",
        "        return elementwise_loss\n",
        "\n",
        "    def _target_hard_update(self):\n",
        "        \"\"\"Hard update: target <- local.\"\"\"\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "                \n",
        "    def _plot(\n",
        "        self, \n",
        "        frame_idx: int, \n",
        "        scores: List[float], \n",
        "        losses: List[float],\n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
        "        plt.plot(scores)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss')\n",
        "        plt.plot(losses)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwoVpeWFefjR"
      },
      "source": [
        "## Environment\n",
        "\n",
        "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwC5cUp3efjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf0bd5b-3bbe-4228-e715-0816cbd7925d"
      },
      "source": [
        "# environment\n",
        "#env_id = \"CartPole-v0\"\n",
        "#env = gym.make(env_id)\n",
        "#if IN_COLAB:\n",
        "#    env = gym.wrappers.Monitor(env, \"videos\", force=True)\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnfKFoa5efjT"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_gC_gz5efjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98eb16d1-3bfb-442a-aed8-00998ebc28a9"
      },
      "source": [
        "seed = 777\n",
        "\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "seed_torch(seed)\n",
        "env.seed(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[777]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_igyxOXefjV"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjeHErr_efjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04b5173-0945-4171-bebe-9a416c92e602"
      },
      "source": [
        "# parameters\n",
        "num_frames = 20000000\n",
        "memory_size = 10000\n",
        "batch_size = 128\n",
        "target_update = 100\n",
        "\n",
        "# train\n",
        "agent = DQNAgent(env, memory_size, batch_size, target_update)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 84, 84]\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vQytPmAefjX"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhIjivuuefjY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "6129e219-556f-4439-b264-576a71269916"
      },
      "source": [
        "agent.train(num_frames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH0G2mzeefjY"
      },
      "source": [
        "## Test\n",
        "\n",
        "Run the trained agent (1 episode)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9FkU7tOefjZ"
      },
      "source": [
        "frames = agent.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf-hvt0aefja"
      },
      "source": [
        "## Render"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiiVTAJaefjb"
      },
      "source": [
        "if IN_COLAB:  # for colab\n",
        "    import base64\n",
        "    import glob\n",
        "    import io\n",
        "    import os\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "    def ipython_show_video(path: str) -> None:\n",
        "        \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
        "        if not os.path.isfile(path):\n",
        "            raise NameError(\"Cannot access: {}\".format(path))\n",
        "\n",
        "        video = io.open(path, \"r+b\").read()\n",
        "        encoded = base64.b64encode(video)\n",
        "\n",
        "        display(HTML(\n",
        "            data=\"\"\"\n",
        "            <video alt=\"test\" controls>\n",
        "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>\n",
        "            \"\"\".format(encoded.decode(\"ascii\"))\n",
        "        ))\n",
        "\n",
        "    list_of_files = glob.glob(\"videos/*.mp4\")\n",
        "    latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    print(latest_file)\n",
        "    ipython_show_video(latest_file)\n",
        "\n",
        "else:  # for jupyter\n",
        "    from matplotlib import animation\n",
        "    from JSAnimation.IPython_display import display_animation\n",
        "    from IPython.display import display\n",
        "\n",
        "\n",
        "    def display_frames_as_gif(frames):\n",
        "        \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
        "        patch = plt.imshow(frames[0])\n",
        "        plt.axis('off')\n",
        "\n",
        "        def animate(i):\n",
        "            patch.set_data(frames[i])\n",
        "\n",
        "        anim = animation.FuncAnimation(\n",
        "            plt.gcf(), animate, frames = len(frames), interval=50\n",
        "        )\n",
        "        display(display_animation(anim, default_mode='loop'))\n",
        "\n",
        "\n",
        "    # display \n",
        "    display_frames_as_gif(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9U6UQI-1SRo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}